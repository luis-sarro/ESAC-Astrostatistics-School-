{
mles[i] <- -loglik4(test[i])
}
plot(test,mles,ty="l")
plot(test,mles,ty="l",ylim=c(-10,10))
test[which(mles>-5)]
test[2]
mles[2]
test[1]
mles[1]
setwd("~/Escritorio/ESAC-Astrostats/2015/session2")
plot(x,y.noise)
n <- length(x)
x <- runif(n)
sigma <- 0.1
eps <- rnorm(n,0,sigma)
y.noise <- 1*x+1+eps
points(x,y.noise,pch=15,col="blue")
abline(1,1)
print(loglik2(coef(mle.order1Poly)[1],coef(mle.order1Poly)[2]))
print(loglik4(coef(mle.sine)))
mle.order1Poly <- mle(loglik2,list(m=0.,c=0.))
mle.order25Poly <- mle(loglik3,list(m1=0, m2=0, m3=0, m4=0,m5=0,m6=0,m7=0,m8=0,m9=0,m10=0,
m11=0, m12=0, m13=0, m14=0,m15=0,m16=0,m17=0,m18=0,m19=0,m20=0,
m21=0, m22=0, m23=0, m24=0,c=0.))
mle.sine <- mle
#Also...
plot(x,y.noise)
n <- length(x)
x <- runif(n)
sigma <- 0.1
eps <- rnorm(n,0,sigma)
y.noise <- 1*x+1+eps
points(x,y.noise,pch=15,col="blue")
abline(1,1)
print(loglik2(coef(mle.order1Poly)[1],coef(mle.order1Poly)[2]))
print(loglik4(coef(mle.sine)))
print(-loglik2(coef(mle.order1Poly)[1],coef(mle.order1Poly)[2]))
print(-loglik4(coef(mle.sine)))
load("dataset.RData")
###########################################################################
y.noise <-y
load("dataset.RData")
y.noise <-y
save.image("endSession2.RData")
setwd("~/Escritorio/ESAC-Astrostats/2015/session3")
setwd("~/Escritorio/ESAC-Astrostats/2015/session3")
load("endSession2.RData")
AIC <- rep(NA,3)
AIC[1] <- -2*logLik(mle.order1Poly)+2*2
AIC[2] <- -2*logLik(mle.order25Poly)+2*25
AIC[3] <- -2*logLik(mle.sine)+2*1
BIC <- rep(NA,3)
BIC[1] <- -2*logLik(mle.order1Poly)+log(25)*2
BIC[2] <- -2*logLik(mle.order25Poly)+log(25)*25
BIC[3] <- -2*logLik(mle.sine)+log(25)*1
AIC
BIC
m=1
c=1
m.min=0
m.max=1.0e3
pi = 1/(m.max-m.min)
cdf.prior <- function(m)
{
cdf <-m/m.max
return(cdf)
}
icdf.prior <- function(cdf)
{
m <-cdf*m.max
return(m)
}
cdf.eq <- seq(0,1,length.out=1000)
m.eq <- icdf.prior(cdf.eq)
plot(m.eq,cdf.eq,ty="l")
cdf.m <- runif(10000,0,1)
m <- icdf.prior(cdf.m)
straight.line <- function(x,m,c)
{
y <- c+m*x
return(y)
}
x <- matrix(seq(-1,1,length.out=100),nrow=10000,ncol=100,byrow=T)
y <- matrix(NA,nrow=10000,ncol=100)
for (i in 1:dim(x)[1])
{
y[i,] <- straight.line(x[i,],m[i],0)
}
plot(x[1,],y[1,],ty="l",xlim=c(-1,1),ylim=c(-1,1))
for (i in 2:dim(x)[1])
{
lines(x[i,],y[i,],col=rgb(0,0,0,0.5))
}
prior.m <- function(m)
{
if (m<0| m> m.max) pi <- 0 else pi = 1/(m.max-m.min)
return(pi)
}
cdf.prior <- function(m)
{
cdf <-m/m.max
return(cdf)
}
m <- seq(-100,1100,length.out = 1200)
m <- seq(-100,1100,length.out = 1200)
plot(m,prior.m(m),ty="l")
prior.m <- function(m)
{
pi <- rep(NA,length(m))
filter.out <- m<0| m> m.max
filter.in <- !filter.out
pi[filter.out] <- 0
pi[filter.in] <- 1/(m.max-m.min)
return(pi)
}
m <- seq(-100,1100,length.out = 1200)
plot(m,prior.m(m),ty="l")
cdf.prior <- function(m)
{
cdf <-m/m.max
return(cdf)
}
plot(m,cdf.prior(m))
plot(m,cdf.prior(m),ty="l")
cdf.prior <- function(m)
{
cdf <-prior.m(m)/m.max
return(cdf)
}
plot(m,cdf.prior(m),ty="l")
cdf.prior <- function(m)
{
cdf <-(max(m,m.min)-m.min)/m.max
return(cdf)
}
plot(m,cdf.prior(m),ty="l")
cdf.prior <- function(m)
{
cdf <-(apply(m,1,max,m.min)-m.min)/m.max
return(cdf)
}
plot(m,cdf.prior(m),ty="l")
cdf.prior <- function(m)
{
cdf <- apply(cbind(m,m.min),1,max)-m.min/m.max
return(cdf)
}
plot(m,cdf.prior(m),ty="l")
cdf.prior <- function(m)
{
cdf <- apply(cbind(apply(cbind(m,m.min),1,max)-m.min,m.max),1,min),1,min)/m.max
return(cdf)
}
plot(m,cdf.prior(m),ty="l")
cdf.prior <- function(m)
{
cdf <- apply(cbind(apply(cbind(m,m.min),1,max)-m.min,m.max),1,min)/m.max
return(cdf)
}
plot(m,cdf.prior(m),ty="l")
icdf.prior <- function(cdf)
{
m <-cdf*m.max
return(m)
}
cdf.eq <- seq(0,1,length.out=1000)
m.eq <- icdf.prior(cdf.eq)
plot(m.eq,cdf.eq,ty="l")
cdf.m <- runif(10000,0,1)
m <- icdf.prior(cdf.m)
pi.theta <- function(theta) return(1/(pi/2))
pi.c <- function(c) return(1/(2-1)) # ... and a harmless flat prior on c.
np <- 100
theta.grid <- seq(0,pi/2,length.out = np)
dtheta <- ((pi/2)-0/np)
c.grid <- seq(0,2,length.out = np)
dc <- (2-0)/np
u.posterior<-matrix(NA,np,np)
loglik2.theta <- function(theta,c)
{
m <- tan(theta)
predicted <- x*m+c
loglik <- dmvnorm(y.noise,predicted,Sigma,log=T) #This time, we do it right, without the minus sign
return(loglik)
}
for (i in 1:np)
{
for (j in 1:np)
{
u.posterior[i,j] <- loglik2.theta(theta.grid[i],c.grid[j])*pi.theta(theta.grid[i])*pi.c(c.grid[j])
}
}
image(theta.grid,c.grid,exp(u.posterior))
Z <- sum(exp(u.posterior)*dtheta*dc)
posterior <- exp(u.posterior)/Z
print(sum(posterior*dtheta*dc))
#posterior averaged deviance
PAD <- 0
for (i in 1:np)
{
for (j in 1:np)
{
PAD <- PAD + posterior[i,j]*loglik2.theta(theta.grid[i],c.grid[j])*dtheta*dc
}
}
# Deviance at posterior mean
PM <- c(0,0)
for (i in 1:np)
{
for (j in 1:np)
{
PM <- PM + c(posterior[i,j]*theta.grid[i]*dtheta*dc,posterior[i,j]*c.grid[j]*dtheta*dc)
}
}
idcs.max <- which(posterior==max(posterior),arr.ind = T)
post.mode <- c(theta.grid[idcs.max[1]],c.grid[idcs.max[2]])
max.lik <-  c(atan(coef(mle.order1Poly)[1]),coef(mle.order1Poly)[2])
DPM <- max(loglik2.theta(PM[1],PM[2]),loglik2.theta(post.mode[1],post.mode[2]),loglik2.theta(max.lik[1],max.lik[2]))
Bayesian.complexity <- -2*(PAD-DPM)
DIC.linear <- DPM - Bayesian.complexity
Sigma
loglik2.theta(PM[1],PM[2])
y.noise
loglik2.theta()
loglik2.theta
Sigma
dim(Sigma)
m
pi.theta <- function(theta) return(1/(pi/2))
pi.c <- function(c) return(1/(2-1)) # ... and a harmless flat prior on c.
np <- 100
theta.grid <- seq(0,pi/2,length.out = np)
dtheta <- ((pi/2)-0/np)
c.grid <- seq(0,2,length.out = np)
dc <- (2-0)/np
u.posterior<-matrix(NA,np,np)
loglik2.theta <- function(theta,c)
{
m <- tan(theta)
predicted <- x*m+c
loglik <- dmvnorm(y.noise,predicted,Sigma,log=T) #This time, we do it right, without the minus sign
return(loglik)
}
for (i in 1:np)
{
for (j in 1:np)
{
u.posterior[i,j] <- loglik2.theta(theta.grid[i],c.grid[j])*pi.theta(theta.grid[i])*pi.c(c.grid[j])
}
}
image(theta.grid,c.grid,exp(u.posterior))
Z <- sum(exp(u.posterior)*dtheta*dc)
posterior <- exp(u.posterior)/Z
print(sum(posterior*dtheta*dc))
loglik2.theta <- function(theta,c)
{
m <- tan(theta)
predicted <- x*m+c
print(size(Sigma))
print(length(predicted))
loglik <- dmvnorm(y.noise,predicted,Sigma,log=T) #This time, we do it right, without the minus sign
return(loglik)
}
for (i in 1:np)
{
for (j in 1:np)
{
u.posterior[i,j] <- loglik2.theta(theta.grid[i],c.grid[j])*pi.theta(theta.grid[i])*pi.c(c.grid[j])
}
}
image(theta.grid,c.grid,exp(u.posterior))
Z <- sum(exp(u.posterior)*dtheta*dc)
posterior <- exp(u.posterior)/Z
print(sum(posterior*dtheta*dc))
loglik2.theta <- function(theta,c)
{
m <- tan(theta)
predicted <- x*m+c
print(size(Sigma))
print(length(predicted))
loglik <- dmvnorm(y.noise,predicted,Sigma,log=T) #This time, we do it right, without the minus sign
return(loglik)
}
loglik2.theta(PM[1],PM[2]),
loglik2.theta(1,1)
loglik2.theta <- function(theta,c)
{
m <- tan(theta)
predicted <- x*m+c
print(dim(Sigma))
print(length(predicted))
loglik <- dmvnorm(y.noise,predicted,Sigma,log=T) #This time, we do it right, without the minus sign
return(loglik)
}
loglik2.theta(1,1)
rm(m)
rm(m) # To be able to reuse the variable
load("endSession2.RData")
rm(list=ls()) # To avoid problems
load("endSession2.RData")
AIC <- rep(NA,3)
AIC[1] <- -2*logLik(mle.order1Poly)+2*2
AIC[2] <- -2*logLik(mle.order25Poly)+2*25
AIC[3] <- -2*logLik(mle.sine)+2*1
print(AIC)
# This suggests that we select the sinusoidal model
# Then, we try with the BIC
BIC <- rep(NA,3)
BIC[1] <- -2*logLik(mle.order1Poly)+log(25)*2
BIC[2] <- -2*logLik(mle.order25Poly)+log(25)*25
BIC[3] <- -2*logLik(mle.sine)+log(25)*1
print(BIC)
pi.theta <- function(theta) return(1/(pi/2))
pi.c <- function(c) return(1/(2-1)) # ... and a harmless flat prior on c.
np <- 100
theta.grid <- seq(0,pi/2,length.out = np)
dtheta <- ((pi/2)-0/np)
c.grid <- seq(0,2,length.out = np)
dc <- (2-0)/np
u.posterior<-matrix(NA,np,np)
loglik2.theta <- function(theta,c)
{
m <- tan(theta)
predicted <- x*m+c
print(dim(Sigma))
print(length(predicted))
loglik <- dmvnorm(y.noise,predicted,Sigma,log=T) #This time, we do it right, without the minus sign
return(loglik)
}
for (i in 1:np)
{
for (j in 1:np)
{
u.posterior[i,j] <- loglik2.theta(theta.grid[i],c.grid[j])*pi.theta(theta.grid[i])*pi.c(c.grid[j])
}
}
image(theta.grid,c.grid,exp(u.posterior))
Z <- sum(exp(u.posterior)*dtheta*dc)
posterior <- exp(u.posterior)/Z
print(sum(posterior*dtheta*dc))
loglik2.theta <- function(theta,c)
{
m <- tan(theta)
predicted <- x*m+c
loglik <- dmvnorm(y.noise,predicted,Sigma,log=T) #This time, we do it right, without the minus sign
return(loglik)
}
for (i in 1:np)
{
for (j in 1:np)
{
u.posterior[i,j] <- loglik2.theta(theta.grid[i],c.grid[j])*pi.theta(theta.grid[i])*pi.c(c.grid[j])
}
}
image(theta.grid,c.grid,exp(u.posterior))
Z <- sum(exp(u.posterior)*dtheta*dc)
posterior <- exp(u.posterior)/Z
print(sum(posterior*dtheta*dc))
PAD <- 0
for (i in 1:np)
{
for (j in 1:np)
{
PAD <- PAD + posterior[i,j]*loglik2.theta(theta.grid[i],c.grid[j])*dtheta*dc
}
}
# Deviance at posterior mean
# First compute the posterior mean
PM <- c(0,0)
for (i in 1:np)
{
for (j in 1:np)
{
PM <- PM + c(posterior[i,j]*theta.grid[i]*dtheta*dc,posterior[i,j]*c.grid[j]*dtheta*dc)
}
}
idcs.max <- which(posterior==max(posterior),arr.ind = T)
post.mode <- c(theta.grid[idcs.max[1]],c.grid[idcs.max[2]])
# ... and the MLE
max.lik <-  c(atan(coef(mle.order1Poly)[1]),coef(mle.order1Poly)[2])
# Visually inspect values
print(PM)
print(post.mode)
print(max.lik)
DPM <- max(loglik2.theta(PM[1],PM[2]),loglik2.theta(post.mode[1],post.mode[2]),loglik2.theta(max.lik[1],max.lik[2]))
Bayesian.complexity <- -2*(PAD-DPM)
DIC.linear <- DPM - Bayesian.complexity
Bayesian.complexity <- -2*(PAD-DPM)
print(Bayesian.complexity)
DIC.linear <- DPM - Bayesian.complexity
print(DIC.linear)
pi.omega <- function(omega) return(1/(2000))
m <- 20000
omega.grid <- seq(0,2000,length.out = m)
domega <- ((2000-0)/m)
u.posterior<- rep(NA,m)
for (i in 1:m)
{
u.posterior[i] <- -loglik4(omega.grid[i])*pi.omega(omega.grid[i])
}
plot(omega.grid,exp(u.posterior),ty="l")
Z <- sum(exp(u.posterior)*domega)
posterior <- exp(u.posterior)/Z
print(sum(posterior*domega))
#posterior averaged deviance
PAD <- 0
for (i in 1:m)
{
PAD <- PAD + posterior[i]*(-loglik4(omega.grid[i]))*domega
}
# Deviance at posterior mean
PM <- c(0)
for (i in 1:m)
{
PM <- PM + posterior[i]*omega.grid[i]*domega
}
idx.max <- which(posterior==max(posterior))
post.mode <- omega.grid[idx.max]
max.lik <-  coef(mle.sine)
DPM <- max(loglik4(PM),loglik4(post.mode),loglik4(max.lik))
Bayesian.complexity <- -2*(PAD-DPM)
DIC.sine <- DPM - Bayesian.complexity
Bayesian.complexity <- -2*(PAD-DPM)
print(Bayesian.complexity)
DIC.sine <- DPM - Bayesian.complexity
print(DIC.sine)
DPM
np <- 100 # Number of points per axis in grid
theta.grid <- seq(0,pi/2,length.out = np)
dtheta <- ((pi/2)-0/np) # The grid step in theta
c.grid <- seq(0,2,length.out = np)
dc <- (2-0)/np # The grid step in c
u.posterior<-matrix(NA,np,np) # Define an empty matrix
# ... and fill it in
for (i in 1:np)
{
for (j in 1:np)
{
u.posterior[i,j] <- loglik2.theta(theta.grid[i],c.grid[j])*pi.theta(theta.grid[i])*pi.c(c.grid[j])
}
}
image(theta.grid,c.grid,exp(u.posterior))
Z <- sum(exp(u.posterior)*dtheta*dc)
posterior <- exp(u.posterior)/Z
print(sum(posterior*dtheta*dc))
#posterior averaged deviance
PAD <- 0
for (i in 1:np)
{
for (j in 1:np)
{
PAD <- PAD + posterior[i,j]*loglik2.theta(theta.grid[i],c.grid[j])*dtheta*dc
}
}
# Deviance at posterior mean
# First compute the posterior mean
PM <- c(0,0)
for (i in 1:np)
{
for (j in 1:np)
{
PM <- PM + c(posterior[i,j]*theta.grid[i]*dtheta*dc,posterior[i,j]*c.grid[j]*dtheta*dc)
}
}
# but also the mode...
idcs.max <- which(posterior==max(posterior),arr.ind = T)
post.mode <- c(theta.grid[idcs.max[1]],c.grid[idcs.max[2]])
# ... and the MLE
max.lik <-  c(atan(coef(mle.order1Poly)[1]),coef(mle.order1Poly)[2])
# Visually inspect values
print(PM)
print(post.mode)
print(max.lik)
DPM <- max(loglik2.theta(PM[1],PM[2]),loglik2.theta(post.mode[1],post.mode[2]),loglik2.theta(max.lik[1],max.lik[2]))
Bayesian.complexity <- -2*(PAD-DPM)
print(Bayesian.complexity)
DIC.linear <- -2*DPM +2* Bayesian.complexity
print(DIC.linear)
pi.omega <- function(omega) return(1/(2000))
m <- 20000
omega.grid <- seq(0,2000,length.out = m)
domega <- ((2000-0)/m)
u.posterior<- rep(NA,m)
for (i in 1:m)
{
u.posterior[i] <- -loglik4(omega.grid[i])*pi.omega(omega.grid[i])
}
plot(omega.grid,exp(u.posterior),ty="l")
Z <- sum(exp(u.posterior)*domega)
posterior <- exp(u.posterior)/Z
print(sum(posterior*domega))
#posterior averaged deviance
PAD <- 0
for (i in 1:m)
{
PAD <- PAD + posterior[i]*(-loglik4(omega.grid[i]))*domega
}
# Deviance at posterior mean
PM <- c(0)
for (i in 1:m)
{
PM <- PM + posterior[i]*omega.grid[i]*domega
}
idx.max <- which(posterior==max(posterior))
post.mode <- omega.grid[idx.max]
max.lik <-  coef(mle.sine)
DPM <- max(loglik4(PM),loglik4(post.mode),loglik4(max.lik))
Bayesian.complexity <- -2*(PAD-DPM)
print(Bayesian.complexity)
DIC.sine <- -2*DPM +2*Bayesian.complexity
print(DIC.sine)
