n2 <- 500
# A points come from a gaussian centered at 0 with a standard deviation 0.3
data.A <- rnorm(n1,0,0.3)
# B points come from a gaussian centered at 2 with a standard deviation 0.3
data.B <- rnorm(n2,2,0.3)
# concatenate the data points and convert to matrix
data <- matrix(c(data.A,data.B))
# Let us have a look at the data
plot(density(data))
points(data,rep(0,length(data)),pch="|")
# Let us further decrease the kernel size
plot(density(data,bw=0.01))
points(data,rep(0,length(data)),pch="|")
# zoom in a region
plot(density(data,bw=0.01),xlim=c(2,3))
points(data,rep(0,length(data)),pch="|")
# zoom back out
plot(density(data))
points(data,rep(0,length(data)),pch="|")
# Tag the class (gaussian) of each point
class <- c(rep(0,n1),rep(1,n2))
# Create a linear discriminant model of the data
lda.mod <- lda(data, class,prior=c(0.5,0.5))
# Use the LDA model to predict the class of each data point
out.class <- predict(lda.mod)$class
# Show results
table(class,out.class)
# We used these points to define the boundary between classes.
# so it comes as no surprise that the model performs well on these data
# Let's see how well it performs on data not used to define the boundary
test.A <- rnorm(n1,0,0.3)
test.B <- rnorm(n2,2,0.3)
test <- matrix(c(test.A,test.B))
test.class <- c(rep(0,n1),rep(1,n2))
out.class <- predict(lda.mod,test)$class
table(test.class,out.class)
# Not bad... not perfect. This is a very easy example to classify,
# unidimensional and with well separated classes. Life is usually not so simple.
# Now, we are going to define a dataset with the same number of points (1000)
# but a lot more variables (1000). The first variable is the same we used in the
# previous exercise. The remaining 999 are drawn from a unique gaussian distribution
# mean=1 and standard deviation = 0.3. These details are not important: what is
# important is the fact that these new variables are irrelevant for the task of
# classifying. Points from classes A and B only differ in the first variable (column).
nr.newfeatures <- 100
nr.newdata <- nr.newfeatures * (n1+n2)
# Add nr.features as columns. Generate de new values from a gaussian distribution (rnorm)
data <- cbind(data,matrix(runif(nr.newdata),ncol=nr.newfeatures))
#data <- cbind(data,matrix(rnorm(nr.newdata,1,0.3),ncol=nr.newfeatures))
# And now, compute a new MULTIVARIATE boundary between the two classes
lda.mod <- lda(data, class,prior=c(0.5,0.5))
out.class <- predict(lda.mod)$class
table(class,out.class)
# Superb! Apparently we lost nothing...
# But... look at what happens with test data
# We now create test data from exactly the same probability density as before
test <-  cbind(test,matrix(runif(nr.newdata),ncol=nr.newfeatures))
#test <-  cbind(test,matrix(rnorm(nr.newdata,1,0.3),ncol=nr.newfeatures))
out.class <- predict(lda.mod,test)$class
table(test.class,out.class)
# Hmmmm, this is almost the same as guessing at random.
# So, irrelevant features are very harmful in some cases. In the best case,
# they increase the CPU and memory consumption
#nb <- naiveBayes(data,as.factor(class))
#l <- predict(nb,test)
# table(class,l)
n1 <- 500
n2 <- 500
# A points come from a gaussian centered at 0 with a standard deviation 0.3
data.A <- rnorm(n1,0,0.3)
# B points come from a gaussian centered at 2 with a standard deviation 0.3
data.B <- rnorm(n2,1,0.3)
# concatenate the data points and convert to matrix
data <- matrix(c(data.A,data.B))
data <- cbind(data,runif(n1+n1))
plot(data)
n1 <- 500
n2 <- 500
# A points come from a gaussian centered at 0 with a standard deviation 0.3
data.A <- rnorm(n1,0,0.4)
# B points come from a gaussian centered at 2 with a standard deviation 0.3
data.B <- rnorm(n2,1,0.3)
# concatenate the data points and convert to matrix
data <- matrix(c(data.A,data.B))
data <- cbind(data,runif(n1+n1))
plot(data)
n1 <- 500
n2 <- 500
# A points come from a gaussian centered at 0 with a standard deviation 0.3
data.A <- rnorm(n1,0,0.4)
# B points come from a gaussian centered at 2 with a standard deviation 0.3
data.B <- rnorm(n2,1,0.4)
# concatenate the data points and convert to matrix
data <- matrix(c(data.A,data.B))
data <- cbind(data,runif(n1+n1))
plot(data)
n1 <- 1000
n2 <- 1000
# A points come from a gaussian centered at 0 with a standard deviation 0.3
data.A <- rnorm(n1,0,0.4)
# B points come from a gaussian centered at 2 with a standard deviation 0.3
data.B <- rnorm(n2,1,0.4)
# concatenate the data points and convert to matrix
data <- matrix(c(data.A,data.B))
data <- cbind(data,runif(n1+n1))
plot(data)
n1 <- 1000
n2 <- 1000
# A points come from a gaussian centered at 0 with a standard deviation 0.3
data.A <- rnorm(n1,0,0.35)
# B points come from a gaussian centered at 2 with a standard deviation 0.3
data.B <- rnorm(n2,1,0.35)
# concatenate the data points and convert to matrix
data <- matrix(c(data.A,data.B))
data <- cbind(data,runif(n1+n1))
plot(data)
n1 <- 1000
n2 <- 1000
# A points come from a gaussian centered at 0 with a standard deviation 0.3
data.A <- rnorm(n1,0,0.3)
# B points come from a gaussian centered at 2 with a standard deviation 0.3
data.B <- rnorm(n2,1,0.3)
# concatenate the data points and convert to matrix
data <- matrix(c(data.A,data.B))
data <- cbind(data,runif(n1+n1))
plot(data)
plot(data[1:n1,],col="red")
points(data[n1+1:n2,],col="orange")
plot(data[1:n1,],col="red",xlim=range(data)[1])
points(data[n1+1:n2,],col="orange")
plot(data[1:n1,],col="red",xlim=c(-1,3),pch=16)
points(data[n1+1:n2,],col="orange",pch=15)
plot(data[1:n1,],col="red",xlim=c(-1,2),pch=16)
points(data[n1+1:n2,],col="orange",pch=15)
apropos("neural")
apropos("nnet")
?nnet
?best.nnet
?tune
require("class")
require("nnet")
class <- c(rep(1,n1),rep(2,n2))
net <- nnet(class ~ data[,1]+data[,2])
net <- nnet(class ~ data[,1]+data[,2],1)
data <- as.data.frame(data,class)
names(data)[1:2] <- c("x1","x2")
dim(data)
data <- as.data.frame(rbind(data,class)
names(data)[1:2] <- c("x1","x2")
data <- as.data.frame(rbind(data,class))
rbind(data,class)
dim(data)
n1 <- 1000
n2 <- 1000
# A points come from a gaussian centered at 0 with a standard deviation 0.3
data.A <- rnorm(n1,0,0.3)
# B points come from a gaussian centered at 2 with a standard deviation 0.3
data.B <- rnorm(n2,1,0.3)
# concatenate the data points and convert to matrix
data <- matrix(c(data.A,data.B))
data <- cbind(data,runif(n1+n1))
class <- c(rep(1,n1),rep(2,n2))
data <- as.data.frame(rbind(data,class)
names(data)[1:2] <- c("x1","x2")
data <- as.data.frame(rbind(data,class))
names(data)[1:2] <- c("x1","x2")
dim(data)
data
n1 <- 1000
n2 <- 1000
# A points come from a gaussian centered at 0 with a standard deviation 0.3
data.A <- rnorm(n1,0,0.3)
# B points come from a gaussian centered at 2 with a standard deviation 0.3
data.B <- rnorm(n2,1,0.3)
# concatenate the data points and convert to matrix
data <- matrix(c(data.A,data.B))
data <- cbind(data,runif(n1+n1))
dim(data)
class <- c(rep(1,n1),rep(2,n2))
data <- as.data.frame(cbind(data,class))
dim(data)
plot(data[1:n1,],col="red",xlim=c(-1,2),pch=16)
points(data[n1+1:n2,],col="orange",pch=15)
plot(data[1:n1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[n1+1:n2,1:2],col="orange",pch=15)
nn <- nnet(class <- x1+x2,2)
?nnet
nn <- nnet(class <- x1+x2,2, data = data)
names(data)[1:2] <- c("x1","x2")
nn <- nnet(class <- x1+x2,2, data = data)
attach(data)
nn <- nnet(class <- x1+x2,2, data = data)
length(x1)
length(x2)
length(class)
nn <- nnet(class ~ x1+x2,2, data = data)
nn <- nnet(class ~ x1+x2,size=2, data = data)
summary(nn)
table(nn$fitted.values,class)
nn <- nnet(class ~ x1+x2,size=2, data = data, softmax=T)
n1 <- 1000
n2 <- 1000
# A points come from a gaussian centered at 0 with a standard deviation 0.3
data.A <- rnorm(n1,0,0.3)
# B points come from a gaussian centered at 2 with a standard deviation 0.3
data.B <- rnorm(n2,1,0.3)
# concatenate the data points and convert to matrix
data <- matrix(c(data.A,data.B))
data <- cbind(data,runif(n1+n1))
class <- cbind(c(rep(1,n1),rep(0,n2)),c(rep(0,n1),rep(1,n2)))
plot(data[1:n1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[n1+1:n2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=clas,size2,softmax=T)
nn <- nnet(x=data, y=class,size2,softmax=T)
nn <- nnet(x=data, y=class,size=2,softmax=T)
res.class <- predict.nnet(nn,data,ty="class")
res.class <- predict(nn,data,ty="class")
res.class <- predict(nn,data,type="class")
res.class <- predict(nn,data)
res.class
class1 <- res.class[1]> res.class[2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=2,softmax=T,reltol=0.0001)
res.class <- predict.nnet(nn,data,ty="class")
class1 <- res.class[1]> res.class[2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=2,softmax=T,reltol=1.0e-10)
res.class <- predict(nn,data)
class1 <- res.class[1]> res.class[2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
sum(class1)
sum(class2)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=2,softmax=T,reltol=1.0e-30)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
?nnet
nn <- nnet(x=data, y=class,size=2,softmax=T,abstol=1.0e-30)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=2,softmax=T,abstol=1.0e-30, maxit=10000)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=2,softmax=T,abstol=1.0e-60, maxit=10000)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
plot(data[1:n1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[n1+1:n2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=2,softmax=T, maxit=10000)
nn$residuals
plot(nn$residuals)
plot(nn$residuals[,1])
nn$value
nn <- nnet(x=data, y=class,size=2,softmax=T, maxit=10000,abstol=1.0e-100)
nn$value
nn <- nnet(x=data, y=class,size=2,softmax=T, maxit=10000,abstol=-1.0e-100)
nn$value
nn <- nnet(x=data, y=class,size=2,softmax=T, maxit=10000,abstol=1)
nn$value
nn <- nnet(x=data, y=class,size=2,softmax=T, maxit=10000,abstol=100)
nn <- nnet(x=data, y=class,size=2,softmax=T, maxit=10000,reltol=100)
nn <- nnet(x=data, y=class,size=2,softmax=T, maxit=10000,reltol=-1)
nn$value
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=5,softmax=T, maxit=10000,reltol=-1)
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
?nnet
nn <- nnet(x=data, y=class,size=5,entropy=T, maxit=10000,reltol=-1)
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=2,softmax=T, maxit=10000)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=2,softmax=T, maxit=10000,reltol=-1)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=5,softmax=T, maxit=10000,reltol=-1)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=15,softmax=T, maxit=10000,reltol=-1)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=55,softmax=T, maxit=10000,reltol=-1)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=200,softmax=T, maxit=10000,reltol=-1)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=150,softmax=T, maxit=10000,reltol=-1)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
?round
round(res.class)
table(class,round(res.class))
length(res.class)
n1 <- 1000
n2 <- 1000
# A points come from a gaussian centered at 0 with a standard deviation 0.3
data.A <- rnorm(n1,0,0.3)
# B points come from a gaussian centered at 2 with a standard deviation 0.3
data.B <- rnorm(n2,1,0.3)
# concatenate the data points and convert to matrix
data <- matrix(c(data.A,data.B))
data <- cbind(data,runif(n1+n1))
class <- cbind(c(rep(1,n1),rep(0,n2)),c(rep(0,n1),rep(1,n2)))
plot(data[1:n1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[n1+1:n2,1:2],col="orange",pch=15)
nn <- nnet(x=data, y=class,size=150,softmax=T, maxit=10000,reltol=-1)
res.class <- predict(nn,data)
class1 <- res.class[,1]> res.class[,2]
class2 <- !class1
table(class,round(res.class))
plot(data[class1,1:2],col="red",xlim=c(-1,2),pch=16)
points(data[class2,1:2],col="orange",pch=15)
dim(data)
length(res.class)
length(class1)
library(MASS)
library(fields)
SetupPalette<-function(c)
{
pal <- colorRampPalette(c("blue","green","yellow","orange","red"),space = "rgb")
nl <- 50
#palette<-pal(nl)
palette <- tim.colors(nl)
col <- c-min(c,na.rm=TRUE)
col <- col/max(col,na.rm=TRUE)
colour <- palette[as.integer(((nl-1)*col)+1)]
return(colour)
}
load("~/Escritorio/m35/iter0.RData")
# mual,mudel,z,H,K,r-z,r-i,J-H
a2 <- ts1.members
a1 <- ts1.nonmembers
k <- kde2d(a1[,1],a1[,2],n=400,h=0.5)
plot(a1[,1],a1[,2],pch=".",xlim=c(-10,10),ylim=c(-10,10))
points(a2[,1],a2[,2],pch=16,col="orange",cex=.5)
contour(k,nlevels=10,add=T,col="red",lwd=3)
library(MASS)
library(fields)
SetupPalette<-function(c)
{
pal <- colorRampPalette(c("blue","green","yellow","orange","red"),space = "rgb")
nl <- 50
#palette<-pal(nl)
palette <- tim.colors(nl)
col <- c-min(c,na.rm=TRUE)
col <- col/max(col,na.rm=TRUE)
colour <- palette[as.integer(((nl-1)*col)+1)]
return(colour)
}
load("~/Escritorio/m35/iter0.RData")
# mual,mudel,z,H,K,r-z,r-i,J-H
a2 <- ts1.members
a1 <- ts1.nonmembers
k <- kde2d(a1[,1],a1[,2],n=400,h=0.5)
plot(a1[,1],a1[,2],pch=".",xlim=c(-10,10),ylim=c(-10,10))
points(a2[,1],a2[,2],pch=16,col="orange",cex=.5)
contour(k,nlevels=10,add=T,col="red",lwd=3)
plot(a1[,6],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(-1,4),xlab="r-i",ylab="r")
points(a2[,6],a2[,6]+a2[,3],pch=".")
plot(a1[,6],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(-1,4),xlab="r-i",ylab="r")
points(a2[,6],a2[,6]+a2[,3],pch=16,cex=.4,col="orange")
plot(a1[,7],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(-1,3),xlab="r-z",ylab="r")
points(a2[,7],a2[,6]+a2[,3],pch=".")
plot(a1[,7],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(-1,3),xlab="r-z",ylab="r")
points(a2[,7],a2[,6]+a2[,3],pch=16,cex=.4,col="orange")
plot(a1[,8],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(-1,3),xlab="J-H",ylab="r")
points(a2[,8],a2[,6]+a2[,3],pch=".")
plot(a1[,8],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(-1,3),xlab="J-H",ylab="r")
points(a2[,8],a2[,6]+a2[,3],pch=16,cex=.4,col="orange")
plot(a1[,8],a1[,5],pch=".",ylim=c(18,9),xlim=c(-0.5,2),xlab="J-H",ylab="K")
points(a2[,8],a2[,5],pch=".")
plot(a1[,8],a1[,5],pch=".",ylim=c(18,9),xlim=c(-0.5,2),xlab="J-H",ylab="K")
points(a2[,8],a2[,5],pch=16,cex=.4,col="orange")
load("~/Escritorio/m35/iter1.RData")
load("~/Escritorio/m35/iter0.RData")
a2 <- ts1.members
a1 <- ts1.nonmembers
col <- SetupPalette(p1.m.m)
par(mar=c(6,5,2,8))
plot(a1[,1],a1[,2],pch=".",xlim=c(-10,10),ylim=c(-10,10))
points(a2[,1],a2[,2],pch=16,col=col,cex=.5)
contour(k,nlevels=10,add=T,col="red",lwd=3)
image.plot(legend.only=TRUE, zlim= range(p1.m.m), horizontal=FALSE, legend.width=3
,reset.graphics=TRUE,axis.args=list(cex.axis=1.),
legend.lab="Membership Probability",legend.mar=6)
t <- rbind(ts1.members,ts1.nonmembers)
k <- kde2d(t[,6],t[,6]+t[,3],n=400,lims=c(-1,4,8,25),h=c(0.1,0.3))
par(mar=c(6,5,2,8))
plot(a1[,6],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(-1,4),xlab="r-i",ylab="r")
points(a2[,6],a2[,6]+a2[,3],pch=16,cex=.4,col=col)
contour(k,add=T,col="red",lwd=3)
image.plot(legend.only=TRUE, zlim= range(p1.m.m), horizontal=FALSE, legend.width=3
,reset.graphics=TRUE,axis.args=list(cex.axis=1.),
legend.lab="Membership Probability",legend.mar=6)
k <- kde2d(t[,6]+t[,3]-t[,5],t[,6]+t[,3],n=400,lims=c(-1,3,8,25),h=c(0.1,0.3))
plot(a1[,6]+a[,3]-a1[,5],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(-1,3),xlab="r-K",ylab="r")
points(a2[,6]+a2[,3]-a2[,5],a2[,6]+a2[,3],pch=16,cex=.4,col=col)
plot(a1[,6]+a1[,3]-a1[,5],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(-1,3),xlab="r-K",ylab="r")
points(a2[,6]+a2[,3]-a2[,5],a2[,6]+a2[,3],pch=16,cex=.4,col=col)
plot(a1[,6]+a1[,3]-a1[,5],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(1,7),xlab="r-K",ylab="r")
points(a2[,6]+a2[,3]-a2[,5],a2[,6]+a2[,3],pch=16,cex=.4,col=col)
plot(a1[,6]+a1[,3]-a1[,5],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(1,7),xlab="r-K",ylab="r")
points(a2[,6]+a2[,3]-a2[,5],a2[,6]+a2[,3],pch=16,cex=.4,col="black")
plot(a1[,6]+a1[,3]-a1[,5],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(1,7),xlab="r-K",ylab="r")
points(a2[,6]+a2[,3]-a2[,5],a2[,6]+a2[,3],pch=".",cex=1,col="black")
k <- kde2d(t[,8],t[,6]+t[,3],n=400,lims=c(-1,3,8,25),h=c(0.1,0.3))
plot(a1[,8],a1[,6]+a1[,3],pch=".",ylim=c(25,8),xlim=c(-1,3),xlab="J-H",ylab="r")
points(a2[,8],a2[,6]+a2[,3],pch=16,cex=.4,col=col)
contour(k,add=T,col="red",lwd=3)
image.plot(legend.only=TRUE, zlim= range(p1.m.m), horizontal=FALSE, legend.width=3
,reset.graphics=TRUE,axis.args=list(cex.axis=1.),
legend.lab="Membership Probability",legend.mar=6)
k <- kde2d(t[,8],t[,5],n=400,lims=c(-0.5,2,9,18),h=c(0.1,0.3))
plot(a1[,8],a1[,5],pch=".",ylim=c(18,9),xlim=c(-0.5,2),xlab="J-H",ylab="K")
points(a2[,8],a2[,5],pch=16,cex=.4,col=col)
contour(k,add=T,col="red",lwd=3)
image.plot(legend.only=TRUE, zlim= range(p1.m.m), horizontal=FALSE, legend.width=3
,reset.graphics=TRUE,axis.args=list(cex.axis=1.),
legend.lab="Membership Probability",legend.mar=6)
k <- kde2d(t[,8],t[,5],n=400,lims=c(-0.5,2,9,18),h=c(0.1,0.3))
plot(a1[,8],a1[,5],pch=".",ylim=c(18,9),xlim=c(-0.5,2),xlab="J-H",ylab="K")
points(a2[,8],a2[,5],pch=16,cex=.4,col=col)
contour(k,add=T,col="red",lwd=3)
image.plot(legend.only=TRUE, zlim= range(p1.m.m), horizontal=FALSE, legend.width=3
,reset.graphics=TRUE,axis.args=list(cex.axis=1.),
legend.lab="Membership Probability",legend.mar=6)
source('~/Escritorio/ESAC-Astrostats/2015/spectrum-MCMC.R')
q("no"")
"
setwd("~/Escritorio/ESAC-Astrostats/2015")
source('~/Escritorio/ESAC-Astrostats/2015/spectrum-MCMC.R')
plot(fit.man$h1)
?extract
fit.man <- extract(fit,inc_warmup=T)
plot(fit.man$h1)
fit.man <- extract(fit,inc_warmup=TRUE)
plot(fit.man$h1)
fit.man$h1
fit.man$h2
fit.man$h3
fit.man$h4
plot(fit.man$h2)
plot(fit.man$h3)
plot(fit.man$h4)
plot(fit.man$h5)
plot(fit.man$h6)
plot(fit.man$w1)
plot(fit.man$h1,fit.man$w1)
plot(fit.man$h2,fit.man$w2)
plot(fit.man$h3,fit.man$w3)
plot(fit.man$h4,fit.man$w4)
plot(fit.man$h5,fit.man$w5)
plot(fit.man$h5,fit.man$w5,col=(rep(1,250),rep(2,250),rep(3,250))
plot(fit.man$h5,fit.man$w5,col=c(rep(1,250),rep(2,250),rep(3,250))
)
plot(fit.man$h1,fit.man$w1,col=c(rep(1,250),rep(2,250),rep(3,250)))
plot(fit.man$h2,fit.man$w2,col=c(rep(1,250),rep(2,250),rep(3,250)))
plot(fit.man$h1,fit.man$h2,col=c(rep(1,250),rep(2,250),rep(3,250)))
q("yes")
